# ADR-0067.2: Graphiti MCP Architecture Decision - Official vs Custom Integration

**Date:** September 22, 2025
**Status:** Proposed
**Tags:** graphiti, mcp, claude-code-cli, neo4j, performance, architecture
**Builds on:** ADR-0067 (Graphiti Temporal Knowledge Graph Enhancement)
**Related:** ADR-0066 (Neo4j Vector Consolidation), ADR-0069 (LLM Enhanced Relationship Detection)

## Executive Summary

This ADR addresses the architectural decision between **using Graphiti's official MCP server** versus **enhancing our custom GraphitiService integration** for optimal Claude Code CLI performance. Following senior engineering analysis, we propose a **structured evaluation approach** with clear decision criteria to determine the optimal path forward for "super fast" Neo4j queries.

## Context

### Current Architecture Crossroads

**✅ Current State (ADR-0067 Phase 3):**
- **Custom Integration**: GraphitiService within neural-tools MCP server
- **Performance**: 11.4s per LLM call (warm), 2-3 minutes per episode
- **Scope**: Batch processing workflows, not interactive

**🎯 New Requirement:**
- **Claude Code CLI Integration**: Enable "super fast" Neo4j queries
- **Performance Target**: Interactive response times (<200ms for simple queries, <2s for complex)
- **User Experience**: Real-time code analysis during development

**🔍 Discovery:**
- **Official Alternative**: Graphiti provides its own MCP server implementation
- **Architecture Question**: Should we migrate to official MCP or enhance custom integration?

### The Strategic Tension

This represents a classic **build vs buy** decision in the context of MCP architecture:

```
Option A: Custom GraphitiService (Build)    vs    Option B: Official Graphiti MCP (Buy)
├── Integrated with neural-tools                  ├── Standalone service
├── Custom business logic                          ├── Vendor-maintained features
├── Known performance characteristics              ├── Unknown performance characteristics
└── Our maintenance burden                         └── Vendor feature velocity
```

## Analysis Framework

### Senior Engineering Perspective

**🔍 Key Questions Identified:**
1. **Origin Story**: Why does our custom GraphitiService exist?
2. **Performance Quantification**: What does "super fast" mean in metrics?
3. **Query Patterns**: What are the most common Claude Code CLI query types?
4. **Business Logic**: Does our custom service contain irreplaceable functionality?

### Architectural Trade-offs Matrix

| Decision Criteria | Custom GraphitiService (Integrated) | Official Graphiti MCP (Standalone) |
|------------------|-------------------------------------|-----------------------------------|
| **Performance** | **Unknown** - Potentially faster (fewer network hops) or slower (resource contention) | **Unknown** - Potentially optimized by vendor, but adds network hop |
| **Maintenance** | **Hidden Cost** - We maintain upgrades, patches, and bugs | **Explicit Cost** - Another service to deploy/monitor, vendor handles core logic |
| **Feature Velocity** | **Low** - We only get new Graphiti features if we build them | **High** - We inherit improvements and features from vendor |
| **Developer Experience** | **Known** - Team understands existing interface | **New** - Requires learning new API/SDK, but might be superior |
| **Separation of Concerns** | **Low** - Graph logic coupled with neural-tools MCP | **High** - Clear boundary, Graphiti MCP owns "graph access" domain |
| **Strategic Alignment** | **Divergent** - Maintaining parallel implementation forever | **Convergent** - Aligned with vendor product roadmap |

## Proposed Decision Framework

### Phase 1: Investigation (1-2 hours)

**🔍 Origin Analysis:**
1. **Git archaeology**: Use `git blame` to understand GraphitiService creation
2. **Business logic audit**: Document custom functionality not available in official MCP
3. **Integration dependencies**: Identify shared concerns (auth, logging, metrics)

**📋 Success Criteria:**
- [ ] Document original purpose of custom GraphitiService
- [ ] Identify irreplaceable custom business logic
- [ ] Map integration touchpoints with neural-tools

### Phase 2: Performance Benchmark (1 day)

**⚡ Empirical Testing:**

**Setup:**
```bash
# Deploy test instance of official Graphiti MCP
docker-compose -f graphiti/mcp_server/docker-compose.yml up -d

# Identify 3 representative query patterns for Claude Code CLI:
# 1. Simple lookup: Find function definition
# 2. Medium traversal: Find all dependencies of a class
# 3. Complex pattern: Trace import chains across modules
```

**Benchmark Script:**
```python
# Execute each query 100 times against both endpoints
# Measure P50, P95, P99 latencies
queries = [
    "MATCH (f:Function {name: 'test_function'}) RETURN f",  # Simple
    "MATCH (c:Class)-[r:DEPENDS_ON*1..3]->(d) RETURN d",   # Medium
    "MATCH path=(m:Module)-[:IMPORTS*]->(target) RETURN path"  # Complex
]
```

**📊 Performance Targets:**
- **Interactive queries**: <200ms response time
- **Data-intensive queries**: <2s response time
- **Throughput**: Support 10+ concurrent CLI users

### Phase 3: Decision Matrix

**✅ Choose Official Graphiti MCP if:**
- Investigation reveals minimal custom business logic
- Performance benchmark shows comparable or better latency
- Strategic alignment with vendor roadmap is valued

**✅ Enhance Custom GraphitiService if:**
- Investigation reveals critical, non-trivial custom business logic
- Performance benchmark shows >30% faster performance on critical query patterns
- Team prefers maintaining full control over graph access layer

## Implementation Strategies

### Option A: Migrate to Official Graphiti MCP

**🏗️ Architecture:**
```
Claude Code CLI
    ↓ (MCP Protocol)
Official Graphiti MCP Server (port 8000)
    ↓ (GraphQL/REST)
Neo4j Database (bolt://localhost:47687)
    ↓ (Container networking)
Docker Compose Infrastructure
```

**🔧 Migration Plan:**
1. **Parallel deployment**: Run both services during transition
2. **Feature parity**: Ensure official MCP supports all required operations
3. **Data migration**: Transfer any custom schemas or indices
4. **Client migration**: Update Claude Code CLI to use official MCP endpoints
5. **Deprecation**: Gradually remove custom GraphitiService

**📦 Dependencies:**
- Official Graphiti MCP Docker image
- MCP client libraries for Claude Code CLI
- Neo4j connection configuration

### Option B: Enhance Custom GraphitiService

**🏗️ Architecture:**
```
Claude Code CLI
    ↓ (MCP Protocol)
Enhanced neural-tools MCP Server
    ├── GraphitiService (optimized)
    ├── Performance caching layer
    └── Query optimization engine
    ↓ (Direct Neo4j driver)
Neo4j Database
```

**🚀 Enhancement Areas:**
1. **Query optimization**: Implement caching and query planning
2. **Connection pooling**: Optimize Neo4j driver configuration
3. **Async processing**: Implement non-blocking query execution
4. **Metrics**: Add performance monitoring and alerting
5. **API optimization**: Design Claude Code CLI-specific endpoints

## Risk Assessment

### Technical Risks

**🔴 High Risk - Official MCP:**
- **API compatibility**: Official MCP might not support all our custom operations
- **Performance regression**: Network hop might impact sub-200ms target
- **Feature gaps**: Official MCP might lack neural-tools-specific optimizations

**🔴 High Risk - Custom Enhancement:**
- **Maintenance burden**: We become responsible for Graphiti feature parity forever
- **Development velocity**: Significant engineering effort required for optimization
- **Strategic drift**: Maintaining parallel implementation diverges from vendor

**🟡 Medium Risk - Both Options:**
- **Migration complexity**: Data and client migration effort
- **Learning curve**: Team needs to adapt to new architecture patterns
- **Performance uncertainty**: Unknown impact on Claude Code CLI user experience

### Mitigation Strategies

**🛡️ Risk Mitigation:**
1. **Dual deployment**: Run both systems in parallel during evaluation
2. **Feature flagging**: Gradual rollout to subset of Claude Code CLI operations
3. **Performance monitoring**: Continuous benchmarking during transition
4. **Rollback plan**: Maintain ability to revert to current architecture
5. **Documentation**: Comprehensive setup and troubleshooting guides

## Success Metrics

### Performance Benchmarks

**📈 Quantitative Targets:**
- **Simple queries**: <200ms P95 latency (function/class lookups)
- **Medium queries**: <1s P95 latency (dependency traversals)
- **Complex queries**: <2s P95 latency (import chain analysis)
- **Concurrent users**: Support 10+ simultaneous Claude Code CLI sessions
- **Throughput**: 100+ queries per minute sustained

**🔍 Quality Metrics:**
- **Uptime**: 99.9% availability during development hours
- **Data consistency**: Zero query result discrepancies vs current system
- **Error rate**: <0.1% failed queries under normal load

### Developer Experience Criteria

**✅ User Experience Goals:**
- **Setup time**: <30 minutes for new developer to configure Claude Code CLI
- **Query discoverability**: IntelliSense/autocomplete for available graph operations
- **Error clarity**: Meaningful error messages for query failures
- **Documentation quality**: Comprehensive examples and troubleshooting guides

## Recommendation Framework

### Default Recommendation

**🎯 Lean towards Official Graphiti MCP unless:**

**Blockers:**
1. **Critical custom logic**: Investigation reveals irreplaceable business functionality
2. **Performance requirements**: Benchmark shows >30% performance degradation
3. **Feature gaps**: Official MCP lacks essential neural-tools integrations

**Strategic Rationale:**
- **Maintenance reduction**: Vendor handles core Graphiti logic and updates
- **Feature velocity**: Automatic access to new Graphiti capabilities
- **Best practices**: Aligned with vendor-recommended architecture patterns
- **Community support**: Broader ecosystem and documentation

### Decision Timeline

**Week 1: Investigation Phase**
- [ ] Complete GraphitiService origin analysis
- [ ] Document custom business logic inventory
- [ ] Identify integration dependencies

**Week 2: Benchmark Phase**
- [ ] Deploy official Graphiti MCP test environment
- [ ] Implement representative query benchmark suite
- [ ] Execute performance comparison testing

**Week 3: Decision & Planning**
- [ ] Apply decision matrix based on investigation + benchmark results
- [ ] Create detailed implementation plan for chosen option
- [ ] Estimate engineering effort and timeline

**Week 4: Implementation Kickoff**
- [ ] Begin implementation of chosen architecture
- [ ] Set up monitoring and performance tracking
- [ ] Document migration plan and rollback procedures

## Future Considerations

### Long-term Strategic Alignment

**📅 Vendor Roadmap Alignment:**
- **GraphQL Evolution**: Graphiti's official API improvements
- **Performance Optimizations**: Vendor-driven caching and query optimization
- **New Features**: Temporal query capabilities, advanced indexing strategies
- **Ecosystem Integration**: Better tooling and debugging support

**🔄 Technology Evolution:**
- **Neo4j Version Updates**: Compatibility with latest database features
- **MCP Protocol Changes**: Adaptation to Model Context Protocol evolution
- **Claude Code CLI Growth**: Scaling to support larger codebases and teams

## Conclusion

ADR-0067.2 establishes a **structured, data-driven approach** to resolving the Graphiti MCP architecture decision. Rather than making an immediate choice, we propose a **time-boxed evaluation process** that will provide empirical evidence for the optimal path forward.

**Key Success Factors:**
1. **Empirical over opinion**: Let performance benchmarks drive the decision
2. **Strategic thinking**: Consider long-term maintenance and alignment costs
3. **Risk mitigation**: Maintain parallel systems during evaluation and transition
4. **User focus**: Prioritize Claude Code CLI developer experience

**Expected Outcome:** A clear, evidence-based recommendation that optimizes for both immediate performance needs and long-term strategic alignment, enabling "super fast" Claude Code CLI queries while minimizing technical debt.

---

**Confidence: 85%** - Comprehensive analysis framework with clear decision criteria, but requires empirical validation through proposed investigation and benchmarking phases.