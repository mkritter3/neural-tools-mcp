#!/usr/bin/env python3
"""Test pattern-based metadata extraction (no LLM required)"""

import asyncio
import json
import sys
import os

# Add path for importing our modules
sys.path.insert(0, '/Users/mkr/local-coding/claude-l9-template/neural-tools/src')

# Import just the classes we need (avoid circular imports)
from servers.services.async_preprocessing_pipeline import MetadataTaggerClient, FileMetadata


async def test_pattern_extraction():
    """Test pattern-based metadata extraction"""
    
    # Create tagger client (won't use LLM)
    tagger = MetadataTaggerClient()
    
    # Test code samples
    test_cases = [
        {
            "name": "Simple utility function",
            "path": "utils/calculator.py",
            "content": """
def calculate_total(items):
    '''Calculate total price of items'''
    total = 0
    for item in items:
        total += item['price'] * item['quantity']
    return total
"""
        },
        {
            "name": "Service class",
            "path": "services/embedding_service.py", 
            "content": """
import numpy as np
from transformers import AutoModel
import asyncio
from typing import List, Optional
import aiohttp

class EmbeddingService:
    '''Service for generating text embeddings'''
    
    def __init__(self, model_name: str = 'bert-base'):
        self.model = AutoModel.from_pretrained(model_name)
        self._cache = {}
    
    async def embed_text(self, text: str) -> np.ndarray:
        # TODO: Add caching logic
        # TODO: Handle rate limiting
        async with aiohttp.ClientSession() as session:
            response = await session.post('/api/embed', json={'text': text})
        return await self.model.encode(text)
    
    async def batch_embed(self, texts: List[str]) -> List[np.ndarray]:
        # FIXME: Optimize batch processing
        results = []
        for text in texts:
            results.append(await self.embed_text(text))
        return results
    
    def _preprocess(self, text: str) -> str:
        # Private method for preprocessing
        return text.lower().strip()
"""
        },
        {
            "name": "Test file",
            "path": "tests/test_calculator.py",
            "content": """
import pytest
from utils.calculator import calculate_total

def test_calculate_total():
    items = [{'price': 10, 'quantity': 2}]
    assert calculate_total(items) == 20
"""
        },
        {
            "name": "Deprecated code",
            "path": "legacy/old_api.py",
            "content": """
# DEPRECATED: Use new_api instead
import os
from typing import Dict, Any

def old_function() -> None:
    '''This function is deprecated'''
    # TODO: Remove in v2.0
    # HACK: Temporary workaround
    with open('config.json', 'r') as f:
        config = f.read()
    pass

async def async_old() -> Dict[str, Any]:
    pass

async def async_old2():
    pass
"""
        }
    ]
    
    print("Testing pattern-based metadata extraction...\n")
    
    for test_case in test_cases:
        print(f"ðŸ“‹ Testing: {test_case['name']}")
        print(f"   File: {test_case['path']}")
        
        # Extract metadata using patterns
        metadata = await tagger.tag_code(
            content=test_case['content'],
            file_path=test_case['path']
        )
        
        print(f"   âœ… Metadata extracted:")
        print(f"      Status: {metadata.status}")
        print(f"      Type: {metadata.component_type}")
        print(f"      Complexity: {metadata.complexity_score}")
        print(f"      Dependencies: {metadata.dependencies}")
        print(f"      Key concepts: {metadata.key_concepts}")
        print(f"      Answers: {metadata.answers_questions}")
        print(f"   ðŸ“Š Optimal Fields (Grok 4 recommended):")
        print(f"      Public API: {metadata.public_api}")
        print(f"      Has type hints: {metadata.has_type_hints}")
        print(f"      TODO count: {metadata.todo_count}")
        print(f"      Has I/O operations: {metadata.has_io_operations}")
        print(f"      Is async-heavy: {metadata.is_async_heavy}")
        print(f"      Line count: {metadata.line_count}")
        print()
    
    print("\n" + "="*60)
    print("âœ… Pattern-based extraction working perfectly!")
    print("ðŸŽ‰ No LLM needed - fast and reliable metadata tagging!")
    print("\nðŸ’¡ Grok 4 Analysis Summary:")
    print("   - 6 optimal fields identified for search quality")
    print("   - Objective, deterministic extraction")
    print("   - Enables powerful compound queries")
    print("   - Examples: 'Find async-heavy services with TODOs'")
    print("            'Show public APIs without type hints'")
    print("            'Find large files with I/O operations'")
    print("="*60)


if __name__ == "__main__":
    print("Testing pattern-based metadata extraction (no LLM)...")
    asyncio.run(test_pattern_extraction())