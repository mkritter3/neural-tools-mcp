#!/bin/bash
# L9 Engineering Deployment Script v2
# Uses GitHub Actions CI/CD validation results for deployment
# Implements ADR-0053, ADR-0045 CI/CD compliance, and ADR-0063 regression prevention

set -euo pipefail

# CRITICAL: Block ANY attempt to bypass tests
# Check for dangerous flags that might bypass validation
for arg in "$@"; do
    case $arg in
        --force|--skip-tests|--no-validation|--bypass|--yolo)
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo "ðŸ›‘ DEPLOYMENT BLOCKED - INVALID FLAG DETECTED: $arg ðŸ›‘"
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo ""
            echo "âš ï¸  Bypassing tests is STRICTLY PROHIBITED"
            echo "âš ï¸  ADR-63 regression tests MUST pass to deploy"
            echo ""
            echo "These flags are blocked to prevent:"
            echo "  - Mount validation regressions"
            echo "  - Container reuse with wrong paths"
            echo "  - Projects only indexing README files"
            echo ""
            echo "If you believe tests are failing incorrectly:"
            echo "  1. Fix the underlying issue"
            echo "  2. Update the tests if requirements changed"
            echo "  3. Get code review approval for changes"
            echo ""
            echo "DO NOT attempt to bypass validation."
            exit 1
            ;;
    esac
done

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
SOURCE_DIR="/Users/mkr/local-coding/claude-l9-template/neural-tools"
TARGET_DIR="/Users/mkr/.claude/mcp-servers/neural-tools"
BACKUP_DIR="/Users/mkr/.claude/mcp-servers/neural-tools-backup-$(date +%Y%m%d-%H%M%S)"

echo -e "${GREEN}ðŸš€ L9 Neural Tools MCP Deployment v2${NC}"
echo "=================================================="
echo -e "${BLUE}Using GitHub Actions CI/CD Pipeline Results${NC}"
echo -e "${RED}ADR-63 Regression Tests: MANDATORY${NC}"
echo ""
echo "Source: $SOURCE_DIR"
echo "Target: $TARGET_DIR"
echo "Backup: $BACKUP_DIR"
echo ""

# Function to check GitHub Actions status
check_github_actions() {
    echo -e "${YELLOW}ðŸ” Checking GitHub Actions CI/CD status...${NC}"

    # Check if gh CLI is installed
    if ! command -v gh &> /dev/null; then
        echo -e "${YELLOW}âš ï¸  GitHub CLI not installed. Install with: brew install gh${NC}"
        echo -e "${YELLOW}Falling back to local validation...${NC}"
        return 1
    fi

    # Check if authenticated
    if ! gh auth status &> /dev/null; then
        echo -e "${YELLOW}âš ï¸  Not authenticated with GitHub. Run: gh auth login${NC}"
        echo -e "${YELLOW}Falling back to local validation...${NC}"
        return 1
    fi

    # Get the latest workflow run status
    echo -e "${BLUE}Fetching latest CI/CD run status...${NC}"

    # Get latest workflow run for main branch (try new modular workflow first)
    LATEST_RUN=$(gh run list \
        --workflow="main.yml" \
        --branch=main \
        --limit=1 \
        --json status,conclusion,headSha,createdAt \
        2>/dev/null || echo "")

    if [ -z "$LATEST_RUN" ]; then
        echo -e "${YELLOW}âš ï¸  No runs found for main.yml. Checking legacy workflows...${NC}"

        # Try the comprehensive workflow (legacy)
        LATEST_RUN=$(gh run list \
            --workflow="neural-tools-comprehensive-ci.yml" \
            --branch=main \
            --limit=1 \
            --json status,conclusion,headSha,createdAt \
            2>/dev/null || echo "")
    fi

    if [ -z "$LATEST_RUN" ] || [ "$LATEST_RUN" = "[]" ]; then
        echo -e "${YELLOW}âš ï¸  No CI/CD runs found for main branch${NC}"
        return 1
    fi

    # Parse the JSON response
    STATUS=$(echo "$LATEST_RUN" | python3 -c "import sys, json; data=json.load(sys.stdin); print(data[0]['conclusion'] if data else 'unknown')" 2>/dev/null || echo "unknown")
    SHA=$(echo "$LATEST_RUN" | python3 -c "import sys, json; data=json.load(sys.stdin); print(data[0]['headSha'][:7] if data else 'unknown')" 2>/dev/null || echo "unknown")
    DATE=$(echo "$LATEST_RUN" | python3 -c "import sys, json; data=json.load(sys.stdin); print(data[0]['createdAt'] if data else 'unknown')" 2>/dev/null || echo "unknown")

    echo ""
    echo "Latest CI/CD Run:"
    echo "  Commit: $SHA"
    echo "  Date: $DATE"
    echo "  Status: $STATUS"
    echo ""

    if [ "$STATUS" = "success" ]; then
        echo -e "${GREEN}âœ… CI/CD validation passed on GitHub Actions${NC}"
        return 0
    else
        echo -e "${RED}âŒ CI/CD validation failed or not completed${NC}"
        echo "Run 'gh workflow run neural-tools-comprehensive-ci.yml' to trigger validation"
        return 1
    fi
}

# Function to run local validation
run_local_validation() {
    echo -e "${YELLOW}ðŸ§ª Running local validation suite...${NC}"

    # Check source directory exists
    if [[ ! -d "$SOURCE_DIR" ]]; then
        echo -e "${RED}âŒ Source directory not found: $SOURCE_DIR${NC}"
        return 1
    fi

    # Check key files exist
    REQUIRED_FILES=(
        "src/neural_mcp/neural_server_stdio.py"
        "src/servers/services/project_context_manager.py"
        "src/servers/services/sync_manager.py"  # ADR-053 WriteSynchronizationManager
        "src/servers/services/indexer_service.py"
        "src/servers/services/pipeline_validation.py"
        "src/servers/services/data_migration_service.py"
        "run_mcp_server.py"
    )

    for file in "${REQUIRED_FILES[@]}"; do
        if [[ ! -f "$SOURCE_DIR/$file" ]]; then
            echo -e "${RED}âŒ Required file missing: $file${NC}"
            return 1
        fi
    done

    # CRITICAL: Run regression prevention tests (ADR-63)
    # These tests MUST pass - no exceptions, no bypassing
    echo ""
    echo -e "${RED}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo -e "${RED}ðŸš¨ CRITICAL REGRESSION TESTS - CANNOT BE BYPASSED ðŸš¨${NC}"
    echo -e "${RED}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo ""

    TESTS_DIR="$SOURCE_DIR/../tests"
    CRITICAL_TESTS=(
        "test_indexer_mount_validation.py"     # ADR-64: Unit tests for mount validation
        "integration/test_indexer_mount_validation.py"  # ADR-64: Integration tests
    )

    # Track test results
    FAILED_TESTS=()
    PASSED_TESTS=()

    # Function to check Docker availability for integration tests
    check_docker_for_integration() {
        if command -v docker &> /dev/null && docker info &> /dev/null; then
            return 0
        else
            echo -e "${YELLOW}âš ï¸  Docker not available - skipping integration tests${NC}"
            return 1
        fi
    }

    # Function to run command with timeout (cross-platform)
    run_with_timeout() {
        local timeout_sec=$1
        shift
        local log_file="${!#}"  # Last argument is log file
        set -- "${@:1:$(($#-1))}"  # Remove last argument

        if command -v timeout &> /dev/null; then
            # Linux/GNU timeout
            timeout "${timeout_sec}s" "$@" > "$log_file" 2>&1
            return $?
        elif command -v gtimeout &> /dev/null; then
            # macOS with coreutils
            gtimeout "${timeout_sec}s" "$@" > "$log_file" 2>&1
            return $?
        else
            # Fallback for macOS - run in background with kill after timeout
            "$@" > "$log_file" 2>&1 &
            local pid=$!
            local count=0
            while [ $count -lt $timeout_sec ]; do
                if ! kill -0 $pid 2>/dev/null; then
                    wait $pid
                    return $?
                fi
                sleep 1
                count=$((count + 1))
            done
            # Timeout reached
            kill -TERM $pid 2>/dev/null
            sleep 2
            kill -KILL $pid 2>/dev/null
            return 124  # timeout exit code
        fi
    }

    for test_file in "${CRITICAL_TESTS[@]}"; do
        if [[ -f "$TESTS_DIR/$test_file" ]]; then
            echo -e "${YELLOW}Running critical test: $test_file${NC}"
            cd "$TESTS_DIR"

            # Skip integration tests if Docker not available
            if [[ "$test_file" == integration/* ]] && ! check_docker_for_integration; then
                echo -e "${YELLOW}âš ï¸  Skipping $test_file (Docker not available)${NC}"
                PASSED_TESTS+=("$test_file (SKIPPED - NO DOCKER)")
                continue
            fi

            # Use timeout for all tests to prevent hangs
            TEST_LOG="/tmp/${test_file//\//_}_output.log"
            if run_with_timeout 300 python3 "$test_file" "$TEST_LOG"; then
                echo -e "${GREEN}âœ… $test_file PASSED${NC}"
                PASSED_TESTS+=("$test_file")
            else
                EXIT_CODE=$?
                if [ $EXIT_CODE -eq 124 ]; then
                    echo -e "${RED}âŒ $test_file TIMEOUT (5min)${NC}"
                    FAILED_TESTS+=("$test_file (TIMEOUT)")
                else
                    echo -e "${RED}âŒ $test_file FAILED${NC}"
                    FAILED_TESTS+=("$test_file")
                fi
                echo "Test output saved to $TEST_LOG"
            fi
        else
            echo -e "${RED}âŒ Critical test missing: $test_file${NC}"
            echo -e "${RED}This test is REQUIRED to prevent mount validation regression${NC}"
            FAILED_TESTS+=("$test_file (MISSING)")
        fi
    done

    # Run ADR-60 E2E tests if available (with timeout and Redis check)
    if [[ -f "$SOURCE_DIR/../scripts/test-adr-60-e2e.py" ]]; then
        echo -e "${YELLOW}Running ADR-60 E2E validation...${NC}"
        cd "$SOURCE_DIR/.."

        # Check Redis availability for E2E tests
        REDIS_AVAILABLE=true
        if ! command -v redis-cli &> /dev/null; then
            echo -e "${YELLOW}âš ï¸  redis-cli not available - E2E tests may use fallback mode${NC}"
            REDIS_AVAILABLE=false
        fi

        # Run with timeout and capture output properly
        if run_with_timeout 600 python3 scripts/test-adr-60-e2e.py "/tmp/adr60_output.log"; then
            if grep -q "ALL TESTS PASSED" /tmp/adr60_output.log; then
                echo -e "${GREEN}âœ… ADR-60 E2E tests passed${NC}"
                PASSED_TESTS+=("ADR-60 E2E")
            else
                echo -e "${YELLOW}âš ï¸  ADR-60 E2E completed but without full success${NC}"
                PASSED_TESTS+=("ADR-60 E2E (PARTIAL)")
            fi
        else
            EXIT_CODE=$?
            if [ $EXIT_CODE -eq 124 ]; then
                echo -e "${RED}âŒ ADR-60 E2E tests timeout (10min)${NC}"
                FAILED_TESTS+=("ADR-60 E2E (TIMEOUT)")
            else
                echo -e "${RED}âŒ ADR-60 E2E tests failed${NC}"
                FAILED_TESTS+=("ADR-60 E2E")
            fi
            echo "E2E test output saved to /tmp/adr60_output.log"
        fi
    fi

    # Run sync manager tests if available (with timeout)
    if [[ -f "$SOURCE_DIR/../scripts/test-sync-manager-integration.py" ]]; then
        echo -e "${YELLOW}Testing WriteSynchronizationManager (ADR-053)...${NC}"
        cd "$SOURCE_DIR/.."
        if run_with_timeout 300 python3 scripts/test-sync-manager-integration.py "/tmp/sync_manager_output.log"; then
            echo -e "${GREEN}âœ… Sync manager validation passed${NC}"
            PASSED_TESTS+=("Sync Manager")
        else
            EXIT_CODE=$?
            if [ $EXIT_CODE -eq 124 ]; then
                echo -e "${RED}âŒ Sync manager validation timeout (5min)${NC}"
                FAILED_TESTS+=("Sync Manager (TIMEOUT)")
            else
                echo -e "${RED}âŒ Sync manager validation failed${NC}"
                FAILED_TESTS+=("Sync Manager")
            fi
            echo "Sync manager output saved to /tmp/sync_manager_output.log"
        fi
    fi

    # Summary
    echo ""
    echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo -e "${BLUE}TEST SUMMARY${NC}"
    echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo -e "${GREEN}Passed: ${#PASSED_TESTS[@]} tests${NC}"
    for test in "${PASSED_TESTS[@]}"; do
        echo -e "  ${GREEN}âœ… $test${NC}"
    done

    if [ ${#FAILED_TESTS[@]} -gt 0 ]; then
        echo -e "${RED}Failed: ${#FAILED_TESTS[@]} tests${NC}"
        for test in "${FAILED_TESTS[@]}"; do
            echo -e "  ${RED}âŒ $test${NC}"
        done
        echo ""
        echo -e "${RED}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
        echo -e "${RED}ðŸ›‘ DEPLOYMENT BLOCKED - CRITICAL TESTS FAILED ðŸ›‘${NC}"
        echo -e "${RED}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
        echo ""
        echo -e "${RED}The ADR-63 mount validation tests are CRITICAL and prevent:${NC}"
        echo -e "${RED}  - Containers being reused with wrong mount paths${NC}"
        echo -e "${RED}  - Projects like neural-novelist only indexing README${NC}"
        echo -e "${RED}  - 409 Docker conflicts during container creation${NC}"
        echo ""
        echo -e "${YELLOW}To fix:${NC}"
        echo "  1. Review test output in /tmp/test_output.log"
        echo "  2. Fix the issues causing test failures"
        echo "  3. Re-run this deployment script"
        echo ""
        echo -e "${RED}âš ï¸  DO NOT attempt to bypass these tests!${NC}"
        echo -e "${RED}âš ï¸  DO NOT comment out test execution!${NC}"
        echo -e "${RED}âš ï¸  DO NOT deploy with --force or --skip-tests!${NC}"
        return 1
    fi

    echo -e "${GREEN}âœ… All critical tests passed${NC}"
    return 0
}

# Main deployment flow
echo -e "${BLUE}ðŸŽ¯ Starting deployment process...${NC}"
echo ""

# Strict CI/CD validation - no bypassing failed CI
VALIDATION_METHOD="none"
CI_CHECK_RESULT=""

# First, always try to check GitHub Actions status
if check_github_actions; then
    VALIDATION_METHOD="github_actions"
    echo -e "${GREEN}âœ… Using GitHub Actions validation results${NC}"
    CI_CHECK_RESULT="success"
else
    # CI check failed - determine if it's unavailable or actually failed
    if ! command -v gh &> /dev/null; then
        echo -e "${YELLOW}âš ï¸  GitHub CLI not available - trying local validation${NC}"
        CI_CHECK_RESULT="cli_unavailable"
    elif ! gh auth status &> /dev/null; then
        echo -e "${YELLOW}âš ï¸  Not authenticated with GitHub - trying local validation${NC}"
        CI_CHECK_RESULT="not_authenticated"
    else
        echo -e "${RED}âŒ CI/CD validation FAILED on GitHub Actions${NC}"
        echo -e "${RED}ðŸ›‘ DEPLOYMENT BLOCKED - CI MUST PASS BEFORE DEPLOYMENT${NC}"
        echo ""
        echo -e "${YELLOW}This is a safety mechanism to prevent broken deployments.${NC}"
        echo ""
        echo "To fix:"
        echo "1. Check GitHub Actions: gh run list --workflow=main.yml"
        echo "2. Fix failing tests or code issues"
        echo "3. Push fixes and wait for CI to pass"
        echo "4. Re-run this deployment script"
        echo ""
        echo "To force deploy despite failed CI (DANGEROUS):"
        echo "  - Remove CI check from this script (not recommended)"
        echo "  - Or fix CI issues first (recommended)"
        exit 1
    fi

    # Only allow local validation if CI is unavailable, not if it failed
    if run_local_validation; then
        VALIDATION_METHOD="local"
        echo -e "${YELLOW}âš ï¸  Using local validation (GitHub Actions unavailable: $CI_CHECK_RESULT)${NC}"
        echo -e "${YELLOW}âš ï¸  This is NOT ideal - consider setting up GitHub CLI for proper CI/CD validation${NC}"
    else
        echo -e "${RED}âŒ Both CI/CD and local validation failed - deployment blocked${NC}"
        echo ""
        echo "Options:"
        echo "1. Fix GitHub Actions CI/CD issues"
        echo "2. Install GitHub CLI: brew install gh"
        echo "3. Fix local validation errors"
        exit 1
    fi
fi

echo ""
echo -e "${YELLOW}ðŸ“¦ Proceeding with deployment...${NC}"

# Create backup
echo -e "${YELLOW}ðŸ’¾ Creating backup...${NC}"
if [[ -d "$TARGET_DIR" ]]; then
    cp -r "$TARGET_DIR" "$BACKUP_DIR"
    echo -e "${GREEN}âœ… Backup created: $BACKUP_DIR${NC}"
else
    echo -e "${YELLOW}âš ï¸ No existing target directory to backup${NC}"
fi

# Deploy with checksum verification
echo -e "${YELLOW}ðŸ“¦ Deploying neural-tools...${NC}"

# Create target directory if it doesn't exist
mkdir -p "$TARGET_DIR"

# Copy files with verification
rsync -av --checksum \
    --exclude='.git' \
    --exclude='__pycache__' \
    --exclude='*.pyc' \
    --exclude='.pytest_cache' \
    --exclude='tests/' \
    "$SOURCE_DIR/" "$TARGET_DIR/"

# Verify critical files
echo -e "${YELLOW}ðŸ” Verifying deployment...${NC}"
REQUIRED_FILES=(
    "src/neural_mcp/neural_server_stdio.py"
    "src/servers/services/sync_manager.py"
    "run_mcp_server.py"
)

for file in "${REQUIRED_FILES[@]}"; do
    if [[ -f "$TARGET_DIR/$file" ]]; then
        echo -e "${GREEN}âœ… $file${NC}"
    else
        echo -e "${RED}âŒ $file - deployment failed${NC}"
        echo -e "${YELLOW}ðŸ”„ Restoring from backup...${NC}"
        rm -rf "$TARGET_DIR"
        if [[ -d "$BACKUP_DIR" ]]; then
            mv "$BACKUP_DIR" "$TARGET_DIR"
        fi
        exit 1
    fi
done

# Set permissions
chmod +x "$TARGET_DIR/run_mcp_server.py"

# Get current git information
CURRENT_SHA=$(cd "$SOURCE_DIR/.." && git rev-parse HEAD 2>/dev/null || echo 'unknown')
CURRENT_BRANCH=$(cd "$SOURCE_DIR/.." && git branch --show-current 2>/dev/null || echo 'unknown')

# Create deployment manifest
cat > "$TARGET_DIR/DEPLOYMENT_MANIFEST.json" << EOF
{
  "deployment_date": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
  "source_commit": "$CURRENT_SHA",
  "source_branch": "$CURRENT_BRANCH",
  "validation_method": "$VALIDATION_METHOD",
  "adr_version": "ADR-0053 WriteSynchronizationManager",
  "deployed_by": "$(whoami)",
  "backup_location": "$BACKUP_DIR",
  "validation_status": "passed",
  "deployment_method": "rsync with checksum verification",
  "features": {
    "write_synchronization": true,
    "atomic_neo4j_qdrant": true,
    "rollback_support": true,
    "sync_metrics": true
  },
  "ci_cd_compliant": true
}
EOF

echo ""
echo -e "${GREEN}ðŸŽ‰ Deployment completed successfully!${NC}"
echo "=================================================="
echo -e "${GREEN}âœ… ADR-053 WriteSynchronizationManager deployed${NC}"
echo -e "${GREEN}âœ… Atomic Neo4j-Qdrant writes enabled${NC}"
echo -e "${GREEN}âœ… Sync metrics and monitoring active${NC}"
echo -e "${GREEN}âœ… Validation method: $VALIDATION_METHOD${NC}"
echo ""

# Check if we should trigger production monitoring
if [ "$VALIDATION_METHOD" = "github_actions" ]; then
    echo -e "${BLUE}ðŸ“Š Production Monitoring${NC}"
    echo "GitHub Actions workflow can trigger monitoring alerts"
    echo "Check: https://github.com/$GITHUB_REPOSITORY/actions"
    echo ""
fi

echo -e "${YELLOW}ðŸ“‹ Next steps:${NC}"
echo "1. Restart Claude outside this project directory"
echo "2. Global MCP will use the updated neural-tools"
echo "3. Monitor sync metrics for >95% success rate"
echo ""

echo -e "${YELLOW}ðŸ’¡ To verify deployment:${NC}"
echo "cd ~  # Leave project directory"
echo "# Restart Claude - it will use global MCP"
echo "# Test neural tools commands"
echo ""

echo -e "${YELLOW}ðŸ”§ Rollback if needed:${NC}"
echo "rm -rf '$TARGET_DIR' && mv '$BACKUP_DIR' '$TARGET_DIR'"
echo ""

if command -v gh &> /dev/null; then
    echo -e "${BLUE}ðŸ“ˆ View CI/CD history:${NC}"
    echo "gh run list --workflow=main.yml"
    echo ""
    echo -e "${BLUE}ðŸš€ Trigger CI/CD manually:${NC}"
    echo "gh workflow run main.yml"
    echo ""
fi

echo -e "${GREEN}ðŸŽ¯ L9 Engineering: CI/CD-compliant deployment complete!${NC}"