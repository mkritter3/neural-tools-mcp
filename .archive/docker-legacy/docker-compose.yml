# Neural Flow MCP Server - Optimized Docker Compose Configuration
# L9-grade performance optimization for vibe coder workflows

version: '3.8'

services:
  neural-flow:
    build: 
      context: .
      target: runtime
      args:
        BUILDKIT_INLINE_CACHE: 1
    image: neural-flow:latest
    container_name: neural-flow-${PROJECT_NAME:-default}
    
    # Optimized volume mounts with performance flags
    volumes:
      # Project-specific data isolation (optimized for performance)
      - type: bind
        source: ./projects/${PROJECT_NAME:-default}/.claude
        target: /app/data
        bind:
          create_host_path: true
      
      # Project source code (read-only with performance optimization)
      - type: bind
        source: ./projects/${PROJECT_NAME:-default}/src
        target: /app/project
        read_only: true
        bind:
          create_host_path: true
      
      # Shared model cache with performance optimization
      - type: volume
        source: neural-flow-models
        target: /app/models
        volume:
          nocopy: false
      
      # Benchmarking results volume
      - type: volume
        source: neural-flow-benchmarks
        target: /app/data/benchmarks
      
    environment:
      # Project identification
      - PROJECT_NAME=${PROJECT_NAME:-default}
      
      # Neural system configuration
      - USE_QODO_EMBED=${USE_QODO_EMBED:-true}
      - ENABLE_AB_TESTING=${ENABLE_AB_TESTING:-true}
      - ENABLE_PERFORMANCE_MONITORING=${ENABLE_PERFORMANCE_MONITORING:-true}
      - ENABLE_BENCHMARKING=${ENABLE_BENCHMARKING:-true}
      
      # Performance optimizations
      - CUDA_VISIBLE_DEVICES=""  # Force CPU for consistency
      - OMP_NUM_THREADS=${OMP_NUM_THREADS:-4}
      - MKL_NUM_THREADS=${MKL_NUM_THREADS:-4}
      - TOKENIZERS_PARALLELISM=false
      
      # Memory management
      - MALLOC_MMAP_THRESHOLD_=131072
      - MALLOC_TRIM_THRESHOLD_=131072
      - MALLOC_TOP_PAD_=131072
      
      # Python optimizations
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - PYTHONOPTIMIZE=2
      
    # Optimized resource limits
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: '3.0'
        reservations:
          memory: 1G
          cpus: '1.0'
    
    # Performance-optimized restart policy
    restart: unless-stopped
    
    # stdio transport for MCP
    stdin_open: true
    tty: true
    
    # Network optimizations
    network_mode: "bridge"
    
    # Security optimization (non-root user)
    user: "1000:1000"
    
    # Optimized logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"
        compress: "true"
    
    # Enhanced health check
    healthcheck:
      test: ["CMD", "python3", "-c", "from neural_embeddings import CodeSpecificEmbedder; print('healthy')"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 45s
    
    # Shared memory for model optimization
    shm_size: 512m
    
    # IPC optimization for multi-process scenarios
    ipc: private

  # Optional: Performance monitoring sidecar
  neural-flow-monitor:
    image: neural-flow:latest
    container_name: neural-flow-monitor-${PROJECT_NAME:-default}
    command: ["/app/monitor-performance.sh"]
    volumes_from:
      - neural-flow
    depends_on:
      - neural-flow
    profiles:
      - monitoring
    restart: unless-stopped
    
  # Optional: Benchmark runner service
  neural-flow-benchmark:
    image: neural-flow:latest
    container_name: neural-flow-benchmark-${PROJECT_NAME:-default}
    command: ["python3", "/app/neural-system/performance_benchmarks.py", "--data-dir", "/app/data"]
    volumes_from:
      - neural-flow
    depends_on:
      - neural-flow
    profiles:
      - benchmarking
    environment:
      - BENCHMARK_MODE=true

volumes:
  # Persistent model cache (shared across projects)
  neural-flow-models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${HOME}/.neural-flow/models
    
  # Benchmarking results storage
  neural-flow-benchmarks:
    driver: local
    driver_opts:
      type: none 
      o: bind
      device: ${HOME}/.neural-flow/benchmarks

networks:
  default:
    driver: bridge
    driver_opts:
      com.docker.network.driver.mtu: 1450