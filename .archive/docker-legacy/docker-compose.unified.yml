# Neural Flow + Qdrant - Unified Docker Compose Configuration
# Project-isolated containers with shared model resources

version: '3.8'

services:
  # Neural Flow MCP Server
  neural-flow:
    build: 
      context: .
      target: runtime
      args:
        BUILDKIT_INLINE_CACHE: 1
    image: neural-flow:latest
    container_name: neural-flow-${PROJECT_NAME:-default}
    
    volumes:
      # Project-specific data isolation
      - type: bind
        source: ./projects/${PROJECT_NAME:-default}/.claude
        target: /app/data
        bind:
          create_host_path: true
      
      # Project source code (read-only)
      - type: bind
        source: ./projects/${PROJECT_NAME:-default}/src
        target: /app/project
        read_only: true
        bind:
          create_host_path: true
      
      # Shared model cache
      - type: volume
        source: neural-models
        target: /app/models
      
      # Benchmarking results
      - type: volume
        source: neural-benchmarks
        target: /app/data/benchmarks
      
    environment:
      # Project identification
      - PROJECT_NAME=${PROJECT_NAME:-default}
      
      # Neural system configuration
      - USE_QODO_EMBED=${USE_QODO_EMBED:-true}
      - ENABLE_AB_TESTING=${ENABLE_AB_TESTING:-true}
      - ENABLE_PERFORMANCE_MONITORING=${ENABLE_PERFORMANCE_MONITORING:-true}
      
      # Qdrant connection (project-specific ports)
      - QDRANT_HOST=qdrant
      - QDRANT_REST_PORT=6333
      - QDRANT_GRPC_PORT=6334
      
      # Performance optimizations
      - OMP_NUM_THREADS=${OMP_NUM_THREADS:-4}
      - MKL_NUM_THREADS=${MKL_NUM_THREADS:-4}
      - TOKENIZERS_PARALLELISM=false
      
      # Python optimizations
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: '3.0'
        reservations:
          memory: 1G
          cpus: '1.0'
    
    restart: unless-stopped
    stdin_open: true
    tty: true
    networks:
      - neural-network
    user: "1000:1000"
    
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"
        compress: "true"
    
    healthcheck:
      test: ["CMD", "python3", "-c", "from neural_embeddings import CodeSpecificEmbedder; print('healthy')"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 45s
    
    shm_size: 512m
    depends_on:
      qdrant:
        condition: service_healthy
  
  # Qdrant Vector Database (Project-specific)
  qdrant:
    image: qdrant/qdrant:v1.10.0
    container_name: qdrant-${PROJECT_NAME:-default}
    
    # Dynamic ports based on project (avoiding enterprise v3 on 6333/6334)
    ports:
      - "${QDRANT_REST_PORT:-6678}:6333"  # REST API
      - "${QDRANT_GRPC_PORT:-6679}:6334"  # gRPC (3-4x faster)
    
    volumes:
      # Project-specific storage
      - type: bind
        source: ./.docker/qdrant/${PROJECT_NAME:-default}/storage
        target: /qdrant/storage
        bind:
          create_host_path: true
      
      - type: bind
        source: ./.docker/qdrant/${PROJECT_NAME:-default}/snapshots
        target: /qdrant/snapshots
        bind:
          create_host_path: true
    
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__SERVICE__HOST=0.0.0.0
      - QDRANT__LOG_LEVEL=INFO
      - QDRANT__STORAGE__STORAGE_PATH=/qdrant/storage
      - QDRANT__STORAGE__SNAPSHOTS_PATH=/qdrant/snapshots
      
      # Performance optimizations
      - QDRANT__STORAGE__WAL__WAL_CAPACITY_MB=32
      - QDRANT__STORAGE__WAL__WAL_SEGMENTS_AHEAD=2
      - QDRANT__STORAGE__PERFORMANCE__INDEXING_THRESHOLD_KB=20000
      - QDRANT__STORAGE__PERFORMANCE__MEMMAP_THRESHOLD_KB=50000
      - QDRANT__STORAGE__PERFORMANCE__PAYLOAD_INDEXING_THRESHOLD_KB=10000
      - QDRANT__STORAGE__OPTIMIZERS__DELETED_THRESHOLD=0.2
      - QDRANT__STORAGE__OPTIMIZERS__VACUUM_MIN_VECTOR_NUMBER=1000
      - QDRANT__STORAGE__OPTIMIZERS__DEFAULT_SEGMENT_NUMBER=4
    
    restart: unless-stopped
    networks:
      - neural-network
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    
    labels:
      project: "${PROJECT_NAME:-default}"
      type: "qdrant-db"
  
  # Shared Model Server for embeddings (saves 90%+ memory)
  model-server:
    build: 
      context: .
      dockerfile: Dockerfile.model-server
      target: model-server
    image: neural-model-server:latest
    container_name: shared-model-server
    ports:
      - "8090:8090"
    volumes:
      - neural-models:/app/models
    environment:
      - MODEL_CACHE_DIR=/app/models
      - PYTHONUNBUFFERED=1
      - OMP_NUM_THREADS=4
      - MKL_NUM_THREADS=4
      - TOKENIZERS_PARALLELISM=false
    networks:
      - neural-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8090/health"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"
        compress: "true"
  
  # Optional: Performance monitoring
  neural-monitor:
    image: neural-flow:latest
    container_name: neural-monitor-${PROJECT_NAME:-default}
    command: ["/app/monitor-performance.sh"]
    volumes_from:
      - neural-flow
    depends_on:
      - neural-flow
    profiles:
      - monitoring
    networks:
      - neural-network
    restart: unless-stopped
  
  # Optional: Benchmark runner
  neural-benchmark:
    image: neural-flow:latest
    container_name: neural-benchmark-${PROJECT_NAME:-default}
    command: ["python3", "/app/neural-system/performance_benchmarks.py"]
    volumes_from:
      - neural-flow
    depends_on:
      - neural-flow
    profiles:
      - benchmarking
    networks:
      - neural-network
    environment:
      - BENCHMARK_MODE=true

volumes:
  # Shared model cache (across all projects)
  neural-models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${HOME}/.neural-flow/models
  
  # Benchmarking results
  neural-benchmarks:
    driver: local
    driver_opts:
      type: none 
      o: bind
      device: ${HOME}/.neural-flow/benchmarks

networks:
  neural-network:
    name: neural-network-${PROJECT_NAME:-default}
    driver: bridge
    driver_opts:
      com.docker.network.driver.mtu: 1450