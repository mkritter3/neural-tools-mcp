#!/usr/bin/env python3
"""
L9 Enhanced MCP Server - 2025 Performance Optimized
Features: Kuzu GraphRAG + Nomic Embed v2-MoE + Tree-sitter + Qdrant hybrid search

Performance Improvements Over Legacy:
- Kuzu GraphRAG (3-10x faster than Neo4j)
- Nomic v2-MoE (30-40% lower inference costs)
- RRF hybrid search with MMR diversity
- INT8 quantization (4x memory reduction)
- Tree-sitter multi-language AST (13+ languages)
"""

import os
import sys
import json
import asyncio
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
import sqlite3

# MCP SDK
from fastmcp import FastMCP
import mcp.types as types

# Qdrant client for enhanced hybrid search (no legacy FastEmbed)
from qdrant_client import QdrantClient
from qdrant_client.http import models
from qdrant_client.http.models import Distance, VectorParams, SparseVectorParams

# Kuzu for GraphRAG
try:
    import kuzu
    KUZU_AVAILABLE = True
except ImportError:
    KUZU_AVAILABLE = False
    logging.warning("Kuzu not available - GraphRAG features disabled")

# Nomic Embed v2 client
import httpx
from dataclasses import dataclass

# Tree-sitter for enhanced code analysis
try:
    from tree_sitter_ast import TreeSitterAnalyzer
    TREE_SITTER_AVAILABLE = True
except ImportError:
    TREE_SITTER_AVAILABLE = False
    logging.warning("Tree-sitter not available - code analysis limited")

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Initialize FastMCP
mcp = FastMCP("l9-neural-enhanced")

# Global clients
qdrant_client = None
kuzu_db = None
kuzu_conn = None
nomic_client = None
ast_analyzer = None

# Constants
QDRANT_HOST = os.environ.get('QDRANT_HOST', 'qdrant')
QDRANT_GRPC_PORT = int(os.environ.get('QDRANT_GRPC_PORT', 6334))
PROJECT_NAME = os.environ.get('PROJECT_NAME', 'default')
COLLECTION_PREFIX = f"project_{PROJECT_NAME}_"
KUZU_DB_PATH = os.environ.get('KUZU_DB_PATH', '/app/kuzu')
GRAPHRAG_ENABLED = os.environ.get('GRAPHRAG_ENABLED', 'true').lower() == 'true'

@dataclass
class NomicEmbedResponse:
    embeddings: List[List[float]]
    model: str
    usage: Dict[str, int]

class NomicEmbedClient:
    """Client for Nomic Embed v2-MoE service"""
    
    def __init__(self):
        host = os.environ.get('EMBEDDING_SERVICE_HOST', 'nomic-embed-service')
        port = int(os.environ.get('EMBEDDING_SERVICE_PORT', 8000))
        self.base_url = f"http://{host}:{port}"
        self.client = httpx.AsyncClient(timeout=60.0)
        
    async def get_embeddings(self, texts: List[str]) -> NomicEmbedResponse:
        """Get embeddings using Nomic Embed v2-MoE"""
        try:
            response = await self.client.post(
                f"{self.base_url}/embed",
                json={"inputs": texts, "normalize": True}
            )
            response.raise_for_status()
            data = response.json()
            
            return NomicEmbedResponse(
                embeddings=data["embeddings"],
                model=data.get("model", "nomic-v2-moe"),
                usage=data.get("usage", {"prompt_tokens": len(texts)})
            )
        except Exception as e:
            logger.error(f"Nomic embed error: {e}")
            raise

async def initialize():
    """Initialize enhanced L9 system with Kuzu GraphRAG"""
    global qdrant_client, kuzu_db, kuzu_conn, nomic_client, ast_analyzer
    
    try:
        # Connect to Qdrant using gRPC (3-4x faster)
        qdrant_client = QdrantClient(
            host=QDRANT_HOST,
            port=QDRANT_GRPC_PORT,
            prefer_grpc=True
        )
        
        # Initialize Nomic Embed v2 client
        nomic_client = NomicEmbedClient()
        
        # Initialize Kuzu GraphRAG if enabled
        if GRAPHRAG_ENABLED and KUZU_AVAILABLE:
            # Ensure the directory exists
            os.makedirs(KUZU_DB_PATH, exist_ok=True)
            # Kuzu Python API expects a database file path, not a directory path
            kuzu_db_file = os.path.join(KUZU_DB_PATH, "graph.db")
            kuzu_db = kuzu.Database(kuzu_db_file)
            kuzu_conn = kuzu.Connection(kuzu_db)
            
            # Initialize graph schema
            await initialize_kuzu_schema()
        
        # Initialize Tree-sitter for code analysis
        if TREE_SITTER_AVAILABLE:
            ast_analyzer = TreeSitterAnalyzer()
        
        # Ensure enhanced collections exist
        await ensure_collection(f"{COLLECTION_PREFIX}memory")
        await ensure_collection(f"{COLLECTION_PREFIX}code")
        await ensure_collection(f"{COLLECTION_PREFIX}docs")
        
        logger.info(f"âœ… Enhanced L9 MCP Server initialized - Project: {PROJECT_NAME}")
        logger.info(f"ðŸ“ Qdrant: {QDRANT_HOST}:{QDRANT_GRPC_PORT}")
        if GRAPHRAG_ENABLED:
            logger.info(f"ðŸ”— Kuzu GraphRAG: {os.path.join(KUZU_DB_PATH, 'graph.db')}")
        logger.info(f"ðŸ§  Nomic Embed v2-MoE: {nomic_client.base_url}")
        
    except Exception as e:
        logger.error(f"Failed to initialize enhanced system: {e}")
        raise

async def initialize_kuzu_schema():
    """Initialize Kuzu graph schema for GraphRAG"""
    try:
        # Create node tables for knowledge entities
        kuzu_conn.execute("""
            CREATE NODE TABLE IF NOT EXISTS Document(
                id STRING, 
                path STRING, 
                content STRING, 
                embedding_id INT64,
                PRIMARY KEY (id)
            )
        """)
        
        kuzu_conn.execute("""
            CREATE NODE TABLE IF NOT EXISTS CodeEntity(
                id STRING,
                name STRING,
                type STRING,
                file_path STRING,
                line_number INT64,
                embedding_id INT64,
                PRIMARY KEY (id)
            )
        """)
        
        kuzu_conn.execute("""
            CREATE NODE TABLE IF NOT EXISTS Concept(
                id STRING,
                name STRING,
                category STRING,
                embedding_id INT64,
                PRIMARY KEY (id)
            )
        """)
        
        # Create relationship tables
        kuzu_conn.execute("""
            CREATE REL TABLE IF NOT EXISTS IMPORTS(
                FROM CodeEntity TO CodeEntity,
                relationship_type STRING
            )
        """)
        
        kuzu_conn.execute("""
            CREATE REL TABLE IF NOT EXISTS REFERENCES(
                FROM Document TO CodeEntity,
                reference_type STRING
            )
        """)
        
        kuzu_conn.execute("""
            CREATE REL TABLE IF NOT EXISTS RELATES_TO(
                FROM Concept TO Concept,
                similarity_score DOUBLE
            )
        """)
        
        logger.info("âœ… Kuzu GraphRAG schema initialized")
        
    except Exception as e:
        logger.error(f"Failed to initialize Kuzu schema: {e}")

async def ensure_collection(collection_name: str):
    """Ensure collection exists with enhanced hybrid search config"""
    try:
        collections = qdrant_client.get_collections().collections
        if not any(c.name == collection_name for c in collections):
            # Create with enhanced configuration
            qdrant_client.create_collection(
                collection_name=collection_name,
                vectors_config={
                    "dense": VectorParams(
                        size=768,  # Nomic Embed v2 dimension
                        distance=Distance.COSINE,
                        hnsw_config=models.HnswConfigDiff(
                            m=32,  # Enhanced connectivity
                            ef_construct=200,  # Better quality
                            full_scan_threshold=10000
                        )
                    ),
                },
                sparse_vectors_config={
                    "sparse": SparseVectorParams(
                        modifier=models.Modifier.IDF
                    )
                },
                quantization_config=models.ScalarQuantization(
                    scalar=models.ScalarQuantizationConfig(
                        type=models.ScalarType.INT8,
                        quantile=0.99,
                        always_ram=True
                    )
                ),
                optimizers_config=models.OptimizersConfigDiff(
                    default_segment_number=8,
                    memmap_threshold=25000,
                    indexing_threshold=10000
                )
            )
            logger.info(f"Created enhanced collection: {collection_name}")
    except Exception as e:
        logger.error(f"Failed to ensure collection: {e}")

@mcp.tool()
async def memory_store_enhanced(
    content: str,
    category: str = "general",
    metadata: Optional[Dict[str, Any]] = None,
    create_graph_entities: bool = True
) -> Dict[str, Any]:
    """Store content with enhanced hybrid indexing and GraphRAG integration
    
    Args:
        content: Text content to store
        category: Category for organization
        metadata: Additional metadata
        create_graph_entities: Whether to create graph entities in Kuzu
    """
    try:
        collection_name = f"{COLLECTION_PREFIX}{category}"
        await ensure_collection(collection_name)
        
        # Generate embeddings using Nomic Embed v2-MoE
        embed_response = await nomic_client.get_embeddings([content])
        dense_embedding = embed_response.embeddings[0]
        
        # Generate sparse embedding (BM25-style)
        # For now, using simple word frequency - could be enhanced with proper BM25
        words = content.lower().split()
        word_freq = {}
        for word in words:
            word_freq[word] = word_freq.get(word, 0) + 1
        
        # Convert to sparse vector format
        vocab_size = 10000  # Simplified vocabulary
        sparse_indices = []
        sparse_values = []
        for word, freq in word_freq.items():
            idx = hash(word) % vocab_size
            sparse_indices.append(idx)
            sparse_values.append(float(freq))
        
        sparse_vector = models.SparseVector(
            indices=sparse_indices,
            values=sparse_values
        )
        
        # Store in Qdrant with enhanced configuration
        point_id = hash(content + str(datetime.now()))
        qdrant_client.upsert(
            collection_name=collection_name,
            points=[
                models.PointStruct(
                    id=abs(point_id) % (10 ** 8),
                    vector={"dense": dense_embedding},
                    sparse_vector={"sparse": sparse_vector},
                    payload={
                        "content": content,
                        "category": category,
                        "timestamp": datetime.now().isoformat(),
                        "model": "nomic-v2-moe",
                        "enhanced": True,
                        **(metadata or {})
                    }
                )
            ]
        )
        
        # Create graph entities if enabled
        graph_entity_id = None
        if create_graph_entities and GRAPHRAG_ENABLED and kuzu_conn:
            try:
                # Create document entity
                doc_id = f"doc_{abs(point_id) % (10 ** 8)}"
                kuzu_conn.execute(
                    f"""
                    CREATE (d:Document {{
                        id: '{doc_id}',
                        path: '{metadata.get('file_path', '')}',
                        content: $content,
                        embedding_id: {abs(point_id) % (10 ** 8)}
                    }})
                    """,
                    parameters={"content": content[:1000]}  # Truncate for storage
                )
                graph_entity_id = doc_id
            except Exception as e:
                logger.warning(f"GraphRAG entity creation failed: {e}")
        
        return {
            "status": "success",
            "id": abs(point_id) % (10 ** 8),
            "collection": collection_name,
            "graph_entity": graph_entity_id,
            "model": "nomic-v2-moe",
            "enhanced": True
        }
        
    except Exception as e:
        logger.error(f"Enhanced store failed: {e}")
        return {"status": "error", "message": str(e)}

@mcp.tool()
async def memory_search_enhanced(
    query: str,
    category: Optional[str] = None,
    limit: int = 10,
    mode: str = "rrf_hybrid",  # Enhanced search modes
    diversity_threshold: float = 0.85,
    graph_expand: bool = True
) -> List[Dict[str, Any]]:
    """Enhanced search with RRF fusion, MMR diversity, and GraphRAG expansion
    
    Args:
        query: Search query
        category: Optional category filter
        limit: Number of results
        mode: Search mode (semantic, keyword, rrf_hybrid, mmr_diverse)
        diversity_threshold: Threshold for MMR diversity
        graph_expand: Whether to expand results using graph relationships
    """
    try:
        collection_name = f"{COLLECTION_PREFIX}{category or 'memory'}"
        
        # Generate query embeddings
        embed_response = await nomic_client.get_embeddings([query])
        dense_embedding = embed_response.embeddings[0]
        
        results = []
        
        if mode in ["semantic", "rrf_hybrid", "mmr_diverse"]:
            # Enhanced dense vector search
            semantic_results = qdrant_client.search(
                collection_name=collection_name,
                query_vector=("dense", dense_embedding),
                limit=limit * 2,  # Get more for fusion/diversity
                with_payload=True,
                with_vectors=True
            )
            
            for hit in semantic_results:
                results.append({
                    "content": hit.payload.get("content"),
                    "score": hit.score,
                    "type": "semantic",
                    "embedding_vector": hit.vector.get("dense") if hit.vector else None,
                    **hit.payload
                })
        
        if mode in ["keyword", "rrf_hybrid"]:
            # Enhanced sparse vector search
            query_words = query.lower().split()
            word_freq = {}
            for word in query_words:
                word_freq[word] = word_freq.get(word, 0) + 1
            
            vocab_size = 10000
            sparse_indices = []
            sparse_values = []
            for word, freq in word_freq.items():
                idx = hash(word) % vocab_size
                sparse_indices.append(idx)
                sparse_values.append(float(freq))
            
            sparse_vector = models.SparseVector(
                indices=sparse_indices,
                values=sparse_values
            )
            
            keyword_results = qdrant_client.search(
                collection_name=collection_name,
                query_vector=models.NamedSparseVector(
                    name="sparse",
                    vector=sparse_vector
                ),
                limit=limit * 2,
                with_payload=True
            )
            
            if mode == "rrf_hybrid":
                # RRF (Reciprocal Rank Fusion) - 2025 state-of-the-art
                for rank, hit in enumerate(keyword_results):
                    content = hit.payload.get("content")
                    # Find semantic match and combine scores
                    semantic_rank = None
                    for s_rank, s_result in enumerate(results):
                        if s_result["content"] == content:
                            semantic_rank = s_rank
                            break
                    
                    if semantic_rank is not None:
                        # RRF formula: score = 1/(k + rank)
                        k = 60  # RRF parameter
                        rrf_score = (1/(k + rank)) + (1/(k + semantic_rank))
                        results[semantic_rank]["score"] = rrf_score
                        results[semantic_rank]["type"] = "rrf_hybrid"
                    else:
                        # Add new keyword result
                        rrf_score = 1/(k + rank)
                        results.append({
                            "content": content,
                            "score": rrf_score,
                            "type": "keyword",
                            **hit.payload
                        })
            else:
                # Pure keyword results
                for hit in keyword_results:
                    results.append({
                        "content": hit.payload.get("content"),
                        "score": hit.score,
                        "type": "keyword",
                        **hit.payload
                    })
        
        # Apply MMR diversity if requested
        if mode == "mmr_diverse" and len(results) > 1:
            results = apply_mmr_diversity(results, diversity_threshold, limit)
        
        # Sort by score and limit
        results.sort(key=lambda x: x["score"], reverse=True)
        results = results[:limit]
        
        # GraphRAG expansion if enabled
        if graph_expand and GRAPHRAG_ENABLED and kuzu_conn:
            try:
                expanded_results = await expand_with_graph_context(results, query)
                return expanded_results
            except Exception as e:
                logger.warning(f"GraphRAG expansion failed: {e}")
        
        return results
        
    except Exception as e:
        logger.error(f"Enhanced search failed: {e}")
        return []

def apply_mmr_diversity(results: List[Dict], threshold: float, limit: int) -> List[Dict]:
    """Apply Maximal Marginal Relevance for result diversification"""
    if not results:
        return results
    
    # Simple MMR implementation using embedding vectors
    selected = [results[0]]  # Start with highest scored result
    remaining = results[1:]
    
    while len(selected) < limit and remaining:
        best_mmr_score = -1
        best_idx = 0
        
        for i, candidate in enumerate(remaining):
            # Calculate relevance score (already have this)
            relevance = candidate["score"]
            
            # Calculate diversity (simple cosine distance from selected)
            diversity = 1.0  # Default high diversity
            if "embedding_vector" in candidate and candidate["embedding_vector"]:
                min_similarity = 1.0
                for selected_item in selected:
                    if "embedding_vector" in selected_item and selected_item["embedding_vector"]:
                        # Simple cosine similarity
                        similarity = cosine_similarity(
                            candidate["embedding_vector"],
                            selected_item["embedding_vector"]
                        )
                        min_similarity = min(min_similarity, similarity)
                diversity = 1 - min_similarity
            
            # MMR formula: Î» * relevance + (1-Î») * diversity
            lambda_param = 0.7  # Balance between relevance and diversity
            mmr_score = lambda_param * relevance + (1 - lambda_param) * diversity
            
            if mmr_score > best_mmr_score:
                best_mmr_score = mmr_score
                best_idx = i
        
        selected.append(remaining.pop(best_idx))
    
    return selected

def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:
    """Calculate cosine similarity between two vectors"""
    if len(vec1) != len(vec2):
        return 0.0
    
    dot_product = sum(a * b for a, b in zip(vec1, vec2))
    magnitude1 = sum(a * a for a in vec1) ** 0.5
    magnitude2 = sum(b * b for b in vec2) ** 0.5
    
    if magnitude1 == 0 or magnitude2 == 0:
        return 0.0
    
    return dot_product / (magnitude1 * magnitude2)

async def expand_with_graph_context(results: List[Dict], query: str) -> List[Dict]:
    """Expand search results using Kuzu graph relationships"""
    try:
        expanded_results = []
        
        for result in results:
            expanded_result = result.copy()
            
            # Find related entities through graph traversal
            if "embedding_id" in result:
                embedding_id = result["embedding_id"]
                
                # Query for related documents and code entities
                graph_query = f"""
                MATCH (d:Document {{embedding_id: {embedding_id}}})-[r:REFERENCES]->(c:CodeEntity)
                RETURN c.name, c.type, c.file_path, r.reference_type
                LIMIT 5
                """
                
                try:
                    graph_results = kuzu_conn.execute(graph_query)
                    if graph_results:
                        related_entities = []
                        for row in graph_results:
                            related_entities.append({
                                "name": row["c.name"],
                                "type": row["c.type"], 
                                "file_path": row["c.file_path"],
                                "relationship": row["r.reference_type"]
                            })
                        
                        expanded_result["graph_context"] = related_entities
                except Exception as e:
                    logger.debug(f"Graph query failed for result {embedding_id}: {e}")
            
            expanded_results.append(expanded_result)
        
        return expanded_results
        
    except Exception as e:
        logger.error(f"Graph expansion failed: {e}")
        return results

@mcp.tool()
async def kuzu_graph_query(query: str) -> Dict[str, Any]:
    """Execute Cypher query on Kuzu graph database
    
    Args:
        query: Cypher query to execute
    """
    try:
        if not GRAPHRAG_ENABLED or not kuzu_conn:
            return {"status": "error", "message": "GraphRAG not enabled"}
        
        result = kuzu_conn.execute(query)
        
        # Convert result to JSON-serializable format
        rows = []
        if result:
            for row in result:
                row_dict = {}
                for key, value in row.items():
                    row_dict[key] = str(value)  # Convert all to strings for JSON
                rows.append(row_dict)
        
        return {
            "status": "success",
            "rows": rows,
            "count": len(rows)
        }
        
    except Exception as e:
        logger.error(f"Kuzu query failed: {e}")
        return {"status": "error", "message": str(e)}

@mcp.tool()
async def performance_stats() -> Dict[str, Any]:
    """Get enhanced system performance statistics"""
    try:
        stats = {
            "timestamp": datetime.now().isoformat(),
            "project": PROJECT_NAME,
            "version": "l9-enhanced-2025"
        }
        
        # Qdrant statistics
        try:
            collections = qdrant_client.get_collections().collections
            qdrant_stats = {}
            total_points = 0
            
            for collection in collections:
                if collection.name.startswith(COLLECTION_PREFIX):
                    info = qdrant_client.get_collection(collection.name)
                    qdrant_stats[collection.name] = {
                        "vectors_count": info.vectors_count,
                        "points_count": info.points_count,
                        "status": info.status,
                        "config": {
                            "distance": info.config.params.vectors.get("dense", {}).get("distance"),
                            "size": info.config.params.vectors.get("dense", {}).get("size")
                        }
                    }
                    total_points += info.points_count
            
            stats["qdrant"] = {
                "collections": qdrant_stats,
                "total_points": total_points,
                "host": QDRANT_HOST
            }
        except Exception as e:
            stats["qdrant"] = {"error": str(e)}
        
        # Kuzu GraphRAG statistics
        if GRAPHRAG_ENABLED and kuzu_conn:
            try:
                # Get node counts
                node_counts = {}
                for table in ["Document", "CodeEntity", "Concept"]:
                    try:
                        result = kuzu_conn.execute(f"MATCH (n:{table}) RETURN count(n) AS count")
                        node_counts[table] = result[0]["count"] if result else 0
                    except:
                        node_counts[table] = 0
                
                # Get relationship counts
                rel_counts = {}
                for table in ["IMPORTS", "REFERENCES", "RELATES_TO"]:
                    try:
                        result = kuzu_conn.execute(f"MATCH ()-[r:{table}]->() RETURN count(r) AS count")
                        rel_counts[table] = result[0]["count"] if result else 0
                    except:
                        rel_counts[table] = 0
                
                stats["kuzu"] = {
                    "database_path": KUZU_DB_PATH,
                    "nodes": node_counts,
                    "relationships": rel_counts,
                    "total_nodes": sum(node_counts.values()),
                    "total_relationships": sum(rel_counts.values())
                }
            except Exception as e:
                stats["kuzu"] = {"error": str(e)}
        else:
            stats["kuzu"] = {"status": "disabled"}
        
        # Nomic Embed statistics
        try:
            health_response = await nomic_client.client.get(f"{nomic_client.base_url}/health")
            if health_response.status_code == 200:
                stats["embedding"] = {
                    "service": "nomic-embed-v2-moe",
                    "status": "healthy",
                    "url": nomic_client.base_url
                }
            else:
                stats["embedding"] = {"status": "unhealthy"}
        except Exception as e:
            stats["embedding"] = {"status": "error", "message": str(e)}
        
        return stats
        
    except Exception as e:
        logger.error(f"Stats failed: {e}")
        return {"status": "error", "message": str(e)}

# Run the enhanced server
if __name__ == "__main__":
    asyncio.run(initialize())
    mcp.run(transport='stdio')