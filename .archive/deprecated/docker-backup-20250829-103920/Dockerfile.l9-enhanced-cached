# L9 Enhanced MCP Server - 2025 Performance Optimized with Docker Cache
# Multi-stage build: Main MCP Server + Nomic Embed v2-MoE Service
# Features: Kuzu GraphRAG + Tree-sitter + Qdrant optimizations + Aggressive Caching

FROM python:3.11-slim as base

# System dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    gcc \
    g++ \
    curl \
    git \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Install Python dependencies with aggressive caching
COPY docker/requirements-l9-enhanced.txt .
RUN --mount=type=cache,target=/root/.cache/pip \
    --mount=type=cache,target=/root/.cache/torch \
    --mount=type=cache,target=/root/.cache/huggingface \
    pip install --no-cache-dir -r requirements-l9-enhanced.txt

# Copy enhanced MCP server (no legacy dependencies)
COPY docker/neural-mcp-server-enhanced.py .
COPY docker/tree_sitter_ast.py .

# Create required directories
RUN mkdir -p /app/data /app/kuzu /app/models

# Set environment variables
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1
ENV L9_VERSION=enhanced-2025-cached

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD python -c "import asyncio; import sys; sys.exit(0)"

# Multi-stage build target selection
# Stage 2: Nomic Embed v2-MoE Service
FROM base as nomic-embed-service

# Copy embedding server
COPY docker/nomic_embed_server.py .

# Set environment for embedding service
ENV EMBEDDING_MODEL=nomic-ai/nomic-embed-text-v2-moe
ENV MODEL_TRUST_REMOTE_CODE=true
ENV MAX_CONCURRENT_REQUESTS=1024
ENV MAX_BATCH_SIZE=100
ENV MAX_BATCH_TOKENS=32768
ENV TORCH_COMPILE=true
ENV FLASH_ATTENTION=true
ENV BATCH_PROCESSING=dynamic
ENV INFERENCE_OPTIMIZATION=true
ENV MOE_ROUTING_EFFICIENCY=0.85

# Expose embedding service port
EXPOSE 8000

# Health check for embedding service
HEALTHCHECK --interval=30s --timeout=15s --start-period=120s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Run Nomic Embed v2-MoE server
CMD ["python", "-m", "uvicorn", "nomic_embed_server:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "1"]

# Stage 3: Default - Main MCP Server (Enhanced)
FROM base as default

# Run the enhanced MCP server
CMD ["python", "neural-mcp-server-enhanced.py"]